---
title: "llm-d 0.5: Reproducible, resilient, and cost-efficient inference at scale"
description: Announcing the llm-d 0.5 release
slug: llm-d-v0.5-reproducible-resilient-cost-efficient-inference-at-scale

authors:
  - robshaw
  - smarterclayton
  - chcost

tags: [releases, announce, llm-d]
---

# llm-d 0.5: Reproducible, resilient, and cost-efficient inference at scale



<!-- truncate -->

![Wide-EP on Nvidia B200](../docs/assets/images/wideep-on-b200.png)

![Single-request KV-cache load across tiers](../docs/assets/images/kvcache-load-across-tiers.png)

![LoRA-precise prefix caching](../docs/assets/images/lora-aware-scheduling.png)